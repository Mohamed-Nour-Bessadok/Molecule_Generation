{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dbfc42b",
   "metadata": {},
   "source": [
    "# üìì Molecule Generator with VAE-based Graph Neural Network (VAE-GNN)\n",
    "This notebook implements a molecule generator based on a Variational Autoencoder (VAE) and Graph Neural Network (GNN), leveraging scaffold-conditioning for improved molecular generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff79189",
   "metadata": {},
   "source": [
    "## üîß Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0703692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720a2a2f",
   "metadata": {},
   "source": [
    "## üß™ Data Preparation: Molecule to Graph Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ce510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mol_to_graph(mol):\n",
    "    nodes = []\n",
    "    edge_index = []\n",
    "\n",
    "    for atom in mol.GetAtoms():\n",
    "        nodes.append([atom.GetAtomicNum()])\n",
    "\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        edge_index.append([i, j])\n",
    "        edge_index.append([j, i])\n",
    "\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    x = torch.tensor(nodes, dtype=torch.float)\n",
    "    return Data(x=x, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acd2915",
   "metadata": {},
   "source": [
    "## üî¨ Graph Network Layer (from scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5f13f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphVAE(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, heads=4, dropout=0.1):\n",
    "        super(GraphVAE, self).__init__(aggr='add')\n",
    "        self.heads = heads\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.lin_q = nn.Linear(in_channels, heads * out_channels)\n",
    "        self.lin_k = nn.Linear(in_channels, heads * out_channels)\n",
    "        self.lin_v = nn.Linear(in_channels, heads * out_channels)\n",
    "        self.lin_out = nn.Linear(heads * out_channels, out_channels)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.norm = nn.LayerNorm(out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        Q = self.lin_q(x).view(-1, self.heads, self.out_channels)\n",
    "        K = self.lin_k(x).view(-1, self.heads, self.out_channels)\n",
    "        V = self.lin_v(x).view(-1, self.heads, self.out_channels)\n",
    "\n",
    "        out = self.propagate(edge_index, Q=Q, K=K, V=V)\n",
    "        out = self.lin_out(out.view(-1, self.heads * self.out_channels))\n",
    "        out = self.norm(out + x)\n",
    "        return out\n",
    "\n",
    "    def message(self, Q_i, K_j, V_j):\n",
    "        score = (Q_i * K_j).sum(dim=-1, keepdim=True) / (self.out_channels ** 0.5)\n",
    "        score = torch.softmax(score, dim=1)\n",
    "        score = self.dropout(score)\n",
    "        return score * V_j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8a2a1a",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Molecule Generator with VAE and Scaffold Conditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb35d91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_GNN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, latent_dim=16, num_layers=4):\n",
    "        super(VAE_GNN, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.layers.append(GraphVAE(in_channels, hidden_channels))\n",
    "            in_channels = hidden_channels\n",
    "        \n",
    "        # VAE specific layers\n",
    "        self.fc_mu = nn.Linear(hidden_channels, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_channels, latent_dim)\n",
    "        self.fc_decode = nn.Linear(latent_dim, hidden_channels)\n",
    "        self.fc_out = nn.Linear(hidden_channels, 1)  \n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, edge_index)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.fc_decode(z))\n",
    "        out = self.fc_out(h)\n",
    "        return out\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        mu, logvar = self.encode(x, edge_index)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        out = self.decode(z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d84130",
   "metadata": {},
   "source": [
    "## üöÄ Training and Sampling Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de35f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy_with_logits(recon_x, x, reduction='sum')\n",
    "    # Kingma & Welling (2013) VAE paper\n",
    "    # Œ≤ is the weight of the KL divergence term\n",
    "    # Higher Œ≤ means more regularization and smoother latent space\n",
    "    # Lower Œ≤ means more freedom for the latent space\n",
    "    Œ≤ = 1.0\n",
    "    # KL divergence term\n",
    "    KL = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + Œ≤ * KL\n",
    "\n",
    "def train(model, loader, optimizer, criterion, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for data in loader:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data.x, data.edge_index)\n",
    "            loss = criterion(out, data.x, data.mu, data.logvar)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f1f7d7",
   "metadata": {},
   "source": [
    "## üî¨ Inference & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8802375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_molecule(model, num_samples=5):\n",
    "    model.eval()\n",
    "    samples = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_samples):\n",
    "            z = torch.randn(1, model.fc_mu.out_features).to(model.fc_mu.weight.device)\n",
    "            sampled_molecule = model.decode(z)\n",
    "            samples.append(sampled_molecule)\n",
    "    return samples\n",
    "\n",
    "def visualize_molecule(molecule_data):\n",
    "    \"\"\"\n",
    "    Visualize the generated molecule using RDKit. \n",
    "    The `molecule_data` is expected to contain atom and bond information in a graph format.\n",
    "    \n",
    "    Parameters:\n",
    "    molecule_data (list): Atom data or a graph object representing the molecule.\n",
    "    \"\"\"\n",
    "    mol = Chem.RWMol()  \n",
    "    \n",
    " \n",
    "    for atom_data in molecule_data['atoms']:  \n",
    "        atom = Chem.Atom(atom_data['atomic_num'])  \n",
    "        mol.AddAtom(atom)\n",
    "    \n",
    "    for bond_data in molecule_data['bonds']:  \n",
    "        bond = Chem.Bond(bond_data['bond_type'])\n",
    "        mol.AddBond(bond_data['start_idx'], bond_data['end_idx'], bond.GetBondType())\n",
    "    \n",
    "    img = Draw.MolToImage(mol)  \n",
    "    display(img)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550a9704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example SMILES\n",
    "\n",
    "smiles_list = pd.read_csv('smiles.csv')['SMILES'].tolist()\n",
    "\n",
    "graph_data = mol_to_graph(smiles_list)\n",
    "\n",
    "data_loader = DataLoader(graph_data, batch_size=2, shuffle=True)\n",
    "\n",
    "latent_dim = 32\n",
    "model = GraphVAE(in_channels=9, hidden_channels=128, latent_dim=latent_dim) \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "train(model, data_loader, optimizer, epochs=10)\n",
    "\n",
    "generate_molecule(model, \"[*:0]NC1CN2CCC1CC2\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
